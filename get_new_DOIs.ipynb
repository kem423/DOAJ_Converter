{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a414c61a",
   "metadata": {},
   "source": [
    "We need to figure out what  DOIs have and have not been deposited with the DOAJ. \n",
    "To do that we pull a list of all DOI from Crossref\n",
    "Check those against the DOAJ API\n",
    "Cram everything into some dataframes and then merge those dataframes so we have a lisr off all DOI, their deposit dates (we want to upload the latest articles first) and their DOAJ upload status. \n",
    "\n",
    "DOAJ docs live: https://doaj.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f641d55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from pandas import json_normalize \n",
    "import requests\n",
    "import datetime\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eff17d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "jrn_code = 'NETN'\n",
    "jrn = 'Network Neuroscience'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d83528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_deposit_status(row):\n",
    "    doi_list = []\n",
    "    respons_list = []\n",
    "    try:\n",
    "        URL = 'https://doaj.org/api/search/articles/doi%3A{}'.format(row['DOI'])\n",
    "        r = requests.get(url = URL)\n",
    "        data = r.json()\n",
    "        response = data['results']\n",
    "        doi_list.append(row['DOI'])\n",
    "        respons_list.append(len(response))\n",
    "        return pd.Series([doi_list, respons_list])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4334632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate list of all DOIs\n",
    "try:\n",
    "    URL = 'https://api.crossref.org/works?filter=container-title:{}&rows=1000&select=DOI,volume,issue,deposited,URL,abstract,author,title&sort=deposited&order=desc'.format(jrn)\n",
    "    r = requests.get(url = URL)\n",
    "    data = r.json()\n",
    "    response = data['message']['items']\n",
    "    json_object = json.dumps(response) \n",
    "    df = pd.json_normalize(response)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa874def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean aand format the date info\n",
    "df['deposited.date-time'] = pd.to_datetime(df['deposited.date-time'])\n",
    "df['deposited.date-time'] = df['deposited.date-time'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# The title comes in as a list so we need to grab just the string\n",
    "df[\"title\"] = df[\"title\"].apply(lambda x: x[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38dd86a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ping DOAJ API to determine whether a DOI has been uploaded. \n",
    "status_df = df.apply(check_deposit_status, axis=1)\n",
    "status_df.columns = ['DOI', 'DOAJ_Deposit_Status']\n",
    "status_df[\"DOI\"] = status_df[\"DOI\"].apply(lambda x: x[0])\n",
    "status_df[\"DOAJ_Deposit_Status\"] = status_df[\"DOAJ_Deposit_Status\"].apply(lambda x: x[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4ec5d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have a DF that includes the DOI, the date deposited to CR< and the DOAJ upload Status\n",
    "result = pd.merge(df, status_df, on=\"DOI\")\n",
    "\n",
    "# We want to filter this to just include those not uploaded to the DOAJ (DOAJ_Deposit_Status=0)\n",
    "result = result[result['DOAJ_Deposit_Status']==0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef661e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.to_csv('{}/result.csv'.format(jrn_code), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeb39397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# status_df.to_csv('{}/status.csv'.format(jrn_code), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b74975b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('{}/{}.csv'.format(jrn_code,jrn_code), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138001c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80d3ee4c",
   "metadata": {},
   "source": [
    "## Convert Crossref JSON into DOAJ XML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee4f359",
   "metadata": {},
   "source": [
    "### Required\n",
    "- Title\n",
    "- Journal title\n",
    "- Publication date\n",
    "- Full-text URL\n",
    "- EISSN\n",
    "\n",
    "### Optional\n",
    "- Authors\n",
    "- Affiliations\n",
    "- Abstracts\n",
    "- Publisher\n",
    "- EISSN\n",
    "- Volume number\n",
    "- Issue number\n",
    "- DOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e1e562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = result[['DOI', 'volume', 'issue', 'deposited.date-time', 'URL']]\n",
    "result.drop(['author', 'deposited.date-parts', 'DOAJ_Deposit_Status', 'deposited.timestamp'], axis=1, inplace=True)\n",
    "result['journalTitle'] = jrn\n",
    "result['eissn'] = '2644-2353'\n",
    "result['language'] = 'eng'\n",
    "result['publisher'] = 'The MIT Press'\n",
    "result.rename(columns={'DOI':'doi', 'URL': 'fullTextUrl1', 'deposited.date-time': 'publicationDate'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc78f476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We got to reorg the cols because the DOAJ schema won;t validate after we convert the DF to XL\n",
    "result = result.loc[:,['language','publisher','journalTitle', 'eissn','publicationDate','volume','issue', 'doi', 'title', 'fullTextUrl1']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9259fcf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      {'10.1162/netn_a_00319': ['Omid Kardan', 'Andr...\n",
       "1      {'10.1162/netn_a_00319': ['Omid Kardan', 'Andr...\n",
       "2      {'10.1162/netn_a_00319': ['Omid Kardan', 'Andr...\n",
       "3      {'10.1162/netn_a_00319': ['Omid Kardan', 'Andr...\n",
       "4      {'10.1162/netn_a_00319': ['Omid Kardan', 'Andr...\n",
       "                             ...                        \n",
       "370    {'10.1162/netn_a_00319': ['Omid Kardan', 'Andr...\n",
       "371    {'10.1162/netn_a_00319': ['Omid Kardan', 'Andr...\n",
       "372    {'10.1162/netn_a_00319': ['Omid Kardan', 'Andr...\n",
       "373    {'10.1162/netn_a_00319': ['Omid Kardan', 'Andr...\n",
       "374    {'10.1162/netn_a_00319': ['Omid Kardan', 'Andr...\n",
       "Length: 375, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I just hate this but we have to deal with the names and this is what I did\n",
    "#  I don;t know...it works \n",
    "dict_names = {}\n",
    "def get_author(row):\n",
    "    names_list = []\n",
    "    try:\n",
    "        for i in range(len(row['author'])):\n",
    "            name = '{} {}'.format(row['author'][i]['given'], row['author'][i]['family'])\n",
    "            try:\n",
    "                aff = row['author'][i]['affiliation'][0]['name']\n",
    "            except IndexError as IE:\n",
    "                pass\n",
    "            names_list.append(name)\n",
    "        dict_names[row['DOI']] = names_list\n",
    "        return dict_names\n",
    "    except IndexError as ie: #no affs, skipping\n",
    "        return dict_names\n",
    "    except TypeError as te: #no authors, skipping\n",
    "        return dict_names\n",
    "    except KeyError as ke: #no given name, skipping\n",
    "       return dict_names\n",
    "df.apply(get_author, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12dbd345",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml = result.to_xml(index=None)\n",
    "tree = ET.ElementTree(ET.fromstring(xml))\n",
    "for row_elem in tree.findall(\"row\"):\n",
    "    row_elem.tag = \"record\"\n",
    "for data_elem in tree.findall(\"data\"):\n",
    "    data_elem.tag = \"records\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11a0b1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for title_elem in tree.findall(\"record\"):\n",
    "    b = ET.SubElement(title_elem, 'authors')\n",
    "    doi = list(title_elem.iter('doi'))[0].text\n",
    "    try:\n",
    "        for name in range(len(dict_names[doi])):\n",
    "            c = ET.SubElement(b, 'author')\n",
    "            d = ET.SubElement(c, 'name')\n",
    "            d.text = dict_names[doi][name]\n",
    "    except KeyError as ke:\n",
    "        continue\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e0b75fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Well this part is just sad to look at...but ET doesn't provide much help and I'm not switching to lxml\n",
    "for record in tree.findall(\"record\"):\n",
    "    sl1 = ET.SubElement(record, 'fullTextUrl')\n",
    "    sl2 = record.find('./fullTextUrl1')\n",
    "    sl1.text = record.find('./fullTextUrl1').text\n",
    "    record.remove(sl2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b51c1225",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtstamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "\n",
    "with open('journals/{}/{}_{}.xml'.format(jrn_code, jrn_code, dtstamp), 'wb') as f:\n",
    "    tree.write(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f463af86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5644af0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
