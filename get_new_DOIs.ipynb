{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8007e40",
   "metadata": {},
   "source": [
    "We need to figure out what HDSR DOIs have and have not been deposited with the DOAJ. \n",
    "To do that we pull a list of all HDSR DOI from Crossref\n",
    "Check those against the DOAJ API\n",
    "Cram everything into some dataframes and then merge those dataframes so we have a lisr off all DOI, their deposit dates (we want to upload the latest articles first) and their DOAJ upload status. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fc73d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from pandas import json_normalize \n",
    "import requests\n",
    "import datetime\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83ed5cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "jrn_code = 'HDSR'\n",
    "jrn = 'Harvard Data Science Review'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b479bfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_deposit_status(row):\n",
    "    doi_list = []\n",
    "    respons_list = []\n",
    "    try:\n",
    "        URL = 'https://doaj.org/api/search/articles/doi%3A{}'.format(row['DOI'])\n",
    "        r = requests.get(url = URL)\n",
    "        data = r.json()\n",
    "        response = data['results']\n",
    "        doi_list.append(row['DOI'])\n",
    "        respons_list.append(len(response))\n",
    "        return pd.Series([doi_list, respons_list])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4334632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START HERE\n",
    "# Generate list of all DOIs\n",
    "try:\n",
    "    URL = 'https://api.crossref.org/works?filter=container-title:{}&rows=1000&select=DOI,volume,issue,deposited,URL,abstract,author,title&sort=deposited&order=desc'.format(jrn)\n",
    "    r = requests.get(url = URL)\n",
    "    data = r.json()\n",
    "    response = data['message']['items']\n",
    "    json_object = json.dumps(response) \n",
    "    df = pd.json_normalize(response)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aab54080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleana and format the date info\n",
    "df['deposited.date-time'] = pd.to_datetime(df['deposited.date-time'])\n",
    "df['deposited.date-time'] = df['deposited.date-time'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# The title comes in as a list so we need to grab just the string\n",
    "df[\"title\"] = df[\"title\"].apply(lambda x: x[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1804daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ping DOAJ API to determin whether a DOI has been uploaded. \n",
    "df = df[0:10]\n",
    "status_df = df.apply(check_deposit_status, axis=1)\n",
    "status_df.columns = ['DOI', 'DOAJ_Deposit_Status']\n",
    "status_df[\"DOI\"] = status_df[\"DOI\"].apply(lambda x: x[0])\n",
    "status_df[\"DOAJ_Deposit_Status\"] = status_df[\"DOAJ_Deposit_Status\"].apply(lambda x: x[0])\n",
    "\n",
    "# status_df['DOI'] = status_df.apply(janky_cleaning_DOI, axis=1)\n",
    "# status_df['DOAJ_Deposit_Status'] = status_df.apply(janky_cleaning_Status, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f88802bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have a DF that includes the DOI, the date deposited to CR< and the DOAJ upload Status\n",
    "result = pd.merge(df, status_df, on=\"DOI\")\n",
    "\n",
    "# We want to filter this to just include those not uploaded to the DOAJ (DOAJ_Deposit_Status=0)\n",
    "result = result[result['DOAJ_Deposit_Status']==0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9d4cea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.to_csv('{}/result.csv'.format(jrn_code), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41bab987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# status_df.to_csv('{}/status.csv'.format(jrn_code), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b74975b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('{}/{}.csv'.format(jrn_code,jrn_code), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e999423a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef828ecb",
   "metadata": {},
   "source": [
    "## Convert Crossref JSON into DOAJ XML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aa9b32",
   "metadata": {},
   "source": [
    "### Required\n",
    "- Title\n",
    "- Journal title\n",
    "- Publication date\n",
    "- Full-text URL\n",
    "- EISSN\n",
    "\n",
    "### Optional\n",
    "- Authors\n",
    "- Affiliations\n",
    "- Abstracts\n",
    "- Publisher\n",
    "- EISSN\n",
    "- Volume number\n",
    "- Issue number\n",
    "- DOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7641f4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = result[['DOI', 'volume', 'issue', 'deposited.date-time', 'URL']]\n",
    "result.drop(['author', 'deposited.date-parts', 'DOAJ_Deposit_Status', 'deposited.timestamp'], axis=1, inplace=True)\n",
    "result['journalTitle'] = jrn\n",
    "result['eissn'] = '2644-2353'\n",
    "result['language'] = 'eng'\n",
    "result['publisher'] = 'The MIT Press'\n",
    "result.rename(columns={'DOI':'doi', 'URL': 'fullTextUrl', 'deposited.date-time': 'publicationDate'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d75213c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'10.1162/99608f92.68a012eb': ['Xiao-Li Meng']...\n",
       "1    {'10.1162/99608f92.68a012eb': ['Xiao-Li Meng']...\n",
       "2    {'10.1162/99608f92.68a012eb': ['Xiao-Li Meng']...\n",
       "3    {'10.1162/99608f92.68a012eb': ['Xiao-Li Meng']...\n",
       "4    {'10.1162/99608f92.68a012eb': ['Xiao-Li Meng']...\n",
       "5    {'10.1162/99608f92.68a012eb': ['Xiao-Li Meng']...\n",
       "6    {'10.1162/99608f92.68a012eb': ['Xiao-Li Meng']...\n",
       "7    {'10.1162/99608f92.68a012eb': ['Xiao-Li Meng']...\n",
       "8    {'10.1162/99608f92.68a012eb': ['Xiao-Li Meng']...\n",
       "9    {'10.1162/99608f92.68a012eb': ['Xiao-Li Meng']...\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_names = {}\n",
    "def get_author(row):\n",
    "    names_list = []\n",
    "    for i in range(len(row['author'])):\n",
    "        name = '{} {}'.format(row['author'][i]['given'], row['author'][i]['family'])\n",
    "        aff = row['author'][i]['affiliation'][0]['name']\n",
    "        names_list.append(name)\n",
    "    dict_names[row['DOI']] = names_list\n",
    "    return dict_names\n",
    "    \n",
    "df.apply(get_author, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a676f85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml = result.to_xml(index=None)\n",
    "tree = ET.ElementTree(ET.fromstring(xml))\n",
    "for row_elem in tree.findall(\"row\"):\n",
    "    row_elem.tag = \"record\"\n",
    "for data_elem in tree.findall(\"data\"):\n",
    "    data_elem.tag = \"records\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "172ac2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andrew Connolly\n",
      "Joseph Hellerstein\n",
      "Naomi Alterman\n",
      "David Beck\n",
      "Rob Fatland\n",
      "Ed Lazowska\n",
      "Vani Mandava\n",
      "Sarah Stone\n",
      "Pavle AvramoviÄ‡\n",
      "Eric Siegel\n",
      "Marta Stelmaszak\n",
      "Kelsey Kline\n",
      "Emily A. Beck\n",
      "Hannah Tavalire\n",
      "Jake Searcy\n",
      "Kavya Mehul Shah\n",
      "Ammaar Ahmed Saeed\n",
      "Joseph K. Blitzstein\n",
      "Thomas B. Berrett\n",
      "Christl A. Donnelly\n"
     ]
    }
   ],
   "source": [
    "for title_elem in tree.findall(\"record\"):\n",
    "    b = ET.SubElement(title_elem, 'authors')\n",
    "    doi = list(title_elem.iter('doi'))[0].text\n",
    "    for name in range(len(dict_names[doi])):\n",
    "        c = ET.SubElement(b, 'author')\n",
    "        d = ET.SubElement(c, 'name')\n",
    "        d.text = dict_names[doi][name]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "313078f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('{}/{}.xml'.format(jrn_code,jrn_code), 'wb') as f:\n",
    "    tree.write(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90ce1af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
